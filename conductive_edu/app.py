
from conductive_edu import algorithm
from conductive_edu.algorithm.agent import Agent
from conductive_edu.config import Config


# è°ƒç”¨å‡½æ•°
def chat_completion():
    # åˆ›å»ºagentå®ä¾‹
    agent = Agent()
    # åˆå§‹åŒ–ä¸€ä¸ªmessagesåˆ—è¡¨
    system_prompt = Config.SYSTEM_PROMPT
    messages = [{
        "role": "system",
        "content": system_prompt
    }]
    # è°ƒç”¨å‡½æ•°
    while True:
        question = input("Question: ")
        if question.lower() in ["exit", "quit"]:   #### è¾“å…¥â€œexitâ€æˆ–â€œquitâ€å¯ä»¥é€€å‡ºå¯¹è¯æ¡†ï¼
            print("Ending conversation.")
            break

        # å°†ç”¨æˆ·é—®é¢˜å­—å…¸å¯¹è±¡æ·»åŠ åˆ°messagesåˆ—è¡¨ä¸­
        messages.append({"role": "user", "content": question})
        # print(messages[-1])
        # è°ƒç”¨APIå¹¶è·å–å“åº”
        response = agent.chat_stream(messages=messages)
        # å°†å¤§æ¨¡å‹çš„å›å¤ä¿¡æ¯æ·»åŠ åˆ°messagesåˆ—è¡¨ä¸­
        messages.append({"role": "assistant", "content": response})
        print("\n")

def embed_completion():
    agent = Agent()
    embedding = agent.embed_stream("ä»€ä¹ˆæ˜¯è¯åˆ¸è¥é”€")
    print("ç”Ÿæˆæ–‡æœ¬åµŒå…¥", embedding)


def generate(question):
    response = agent_executor.invoke({"question": question})
    return response.get("output")

import gradio as gr
with gr.Blocks() as demo:
    gr.Markdown("# Gradio Demo UI ğŸ–ï¸")
    input_text = gr.Text(label="Your Input")
    btn = gr.Button("Submit")
    result = gr.Textbox(label="Generated Result")

    btn.click(fn=generate, inputs=[input_text], outputs=[result])

gr.close_all()
demo.launch()

if __name__ == "__main__":
    agent = Agent()
    file_path = "G:\PycharmProjects\education_llm\conductive_edu\data\knowledge.pdf"
    agent.embed_api(file_path)
    # chat_completion()
    # embed_completion()


